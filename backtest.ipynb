{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'Derek Qi'\n",
    "# Doing portfolio backtest and generates output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from time import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from setup.univ_setup import *\n",
    "from factor_mining.combine_factors import *\n",
    "from factor_mining.factor_model_regression import *\n",
    "from factor_mining.factor_preprocessing import *\n",
    "\n",
    "from factor_model.stock_ret_est import GenReturn \n",
    "from GenPosition import *\n",
    "from backtest_main import *\n",
    "from performance_analysis.pa_core import *\n",
    "\n",
    "from factor_mining.factors.momentum import *\n",
    "\n",
    "from factor_mining.Mark0 import * # This is alpha file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backtest_single_period(univ, factor_exp_mat, ret_series, t, silent=True):\n",
    "\t'''\n",
    "\tDo a single period backtest on univ[t]\n",
    "\tt: datetime object that is one of the element in keys of univ\n",
    "\tfactor_exp_mat, ret_series: factor exposure and return time series\n",
    "\t'''\n",
    "\t# Set backtest params\n",
    "\tlookback = timedelta(weeks=30)\n",
    "\tdend = t\n",
    "\tdstart = dend - lookback\n",
    "\n",
    "\t# Fit single period factor return\n",
    "\tfr, fr_mse = factor_model_fit(factor_exp_mat, ret_series, dstart, dend, weight='vol10')\n",
    "\n",
    "\tfx = factor_exp_mat[dend]\n",
    "\tfx = fx.dropna()\n",
    "\t# Filt the available pool\n",
    "\tuniv_fin = univ[dend]\n",
    "# \tuniv_fin = univ_fin.dropna()\n",
    "# \t# Throw away penny stocks\n",
    "# \tuniv_fin = filt_byval_single_period(univ_fin, 'price', 10)\n",
    "# \t# Throw away illiquid stocks\n",
    "# \tuniv_fin = filt_byval_single_period(univ_fin, 'volume', 1500000)\n",
    "# \t# Throw away things in MA\n",
    "# \tuniv_fin = filt_byval_single_period(univ_fin, 'inMA', 0)\n",
    "\tfx = pd.merge(fx, univ_fin[['ticker']], how='inner', on='ticker')\n",
    "\n",
    "# \tif 0:\n",
    "# \t\tfx.to_csv('./temp/factor_exposure_' + t.strftime('%Y%m%d') + '.csv', index=False)\n",
    "# \t\tfr.to_csv('./temp/factor_return_' + t.strftime('%Y%m%d') + '.csv', index=False)\n",
    "\n",
    "\t# Calculate position\n",
    "\tstock_list, w_opt = GenPosition(fr, fx, U=0.2)\n",
    "\tw_opt = PositionFilter(w_opt) # filt away very small number in portfolio\n",
    "\tptfl_full = pd.DataFrame({\"ticker\": stock_list, \"weight\": list(w_opt.T[0])})\n",
    "\tptfl_full = pd.merge(ptfl_full, univ_fin[['ticker', 'f_log_ret_1']], how='inner', on='ticker')\n",
    "\tptfl_full.loc[ptfl_full.f_log_ret_1 < -2.5, 'f_log_ret_1'] = 0 # Emergency process for stocks in MA for over 6 months\n",
    "\tpnl_sp = np.dot(ptfl_full.weight, ptfl_full.f_log_ret_1)\n",
    "\n",
    "\tif not silent:\n",
    "\t\tprint('Pool size: %d' % univ_fin.shape[0])\n",
    "\t\tprint(ptfl_full[ptfl_full['weight'] != 0])\n",
    "\t\tprint('Period log pnl: %f' % pnl_sp)\n",
    "\treturn ptfl_full, pnl_sp, np.mean(fr)\n",
    "\n",
    "\n",
    "def backtest_multi_period_rebalance(univ, factor_exp_mat, ret_series, dstart, dend, rebalance, silent=True):\n",
    "\t'''\n",
    "\tBacktest with multi-period rebalancing\n",
    "\t'''\n",
    "\tdatelst = sorted(univ.keys())\n",
    "\ttin_lst, ptfl_lst, pnl_lst = [], [], []\n",
    "\tfactor_names = factor_exp_mat[datelst[0]].columns[2:].tolist() # exclude date and ticker column\n",
    "\tfr_df = pd.DataFrame(columns = factor_names)\n",
    "\tcount = 0\n",
    "\tfor ti in range(len(datelst)):\n",
    "\t\tt = datelst[ti]\n",
    "\t\t\n",
    "\t\tif t < dstart or t > dend:\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\tif not silent:\n",
    "\t\t\tprint(t)\n",
    "\t\t\n",
    "\t\ttin_lst.append(t)\n",
    "\t\t\n",
    "\t\tif count == 0:\n",
    "\t\t\t# Do rebalance\n",
    "\t\t\tptfl, pnl_sp, fr_sp = backtest_single_period(univ, factor_exp_mat, ret_series, t, silent)\n",
    "\t\t\tptfl_lst.append(ptfl)\n",
    "\t\t\tpnl_lst.append(pnl_sp)\n",
    "\t\t\tfr_df = fr_df.append(fr_sp, ignore_index=True)\n",
    "\t\telse:\n",
    "\t\t\t# Use prev portfolio\n",
    "\t\t\tptfl = ptfl_lst[-1].copy()\n",
    "\t\t\tptfl = ptfl[['ticker','weight']]\n",
    "\t\t\t# Filt the available pool\n",
    "\t\t\tuniv_fin = univ[t]\n",
    "# \t\t\tuniv_fin = univ_fin.dropna()\n",
    "# \t\t\t# Throw away penny stocks\n",
    "# \t\t\tuniv_fin = filt_byval_single_period(univ_fin, 'price', 10)\n",
    "# \t\t\t# Throw away illiquid stocks\n",
    "# \t\t\tuniv_fin = filt_byval_single_period(univ_fin, 'volume', 1500000)\n",
    "# \t\t\t# Throw away things in MA\n",
    "# \t\t\tuniv_fin = filt_byval_single_period(univ_fin, 'not_in_MA', 0)\n",
    "\t\t\t\n",
    "\t\t\t# Force clear what is not in the pool now and re-normalize the weight\n",
    "\t\t\tptfl = pd.merge(ptfl, univ_fin[['ticker', 'f_log_ret_1']], how='inner', on='ticker')\n",
    "\t\t\tptfl.loc[ptfl.f_log_ret_1 < -2.5, 'f_log_ret_1'] = 0 # Emergency process for stocks in MA for over 6 months\n",
    "\t\t\tpnl_sp = np.dot(ptfl.weight, ptfl.log_ret)\n",
    "\t\t\t\n",
    "\t\t\tptfl_lst.append(ptfl)\n",
    "\t\t\tpnl_lst.append(pnl_sp)\n",
    "\t\t\tfr_df = fr_df.append(fr_sp, ignore_index=True)\n",
    "\t\t\t\n",
    "\t\t\tif not silent:\n",
    "\t\t\t\tprint('Pool size: %d' % univ_fin.shape[0])\n",
    "\t\t\t\tprint(ptfl[ptfl['weight'] != 0])\n",
    "\t\t\t\tprint('Period log pnl: %f' % pnl_sp)\t\n",
    "\t\tcount -= 1\n",
    "\t\tcount %= rebalance\n",
    "\tpnl = pd.DataFrame({'date': tin_lst, 'pnl': pnl_lst})\n",
    "# \tprint(fr_df.shape, len(tin_lst))\n",
    "\tfr_df['date'] = tin_lst\n",
    "\tfr_df = fr_df[['date'] + factor_names]\n",
    "\treturn ptfl, pnl, fr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### universe setup ###\n",
    "print('Setup R3000 universe')\n",
    "datadir = '/home/derek-qi/Documents/R3000_Data/data/r3000/'\n",
    "start = time()\n",
    "if os.path.exists(datadir + 'univ.pkl'):\n",
    "    print('use existing binary file')\n",
    "    with open(datadir + 'univ.pkl', 'rb') as univ_fh:\n",
    "        univ = pickle.load(univ_fh)\n",
    "    \n",
    "else:\n",
    "    print('construct from csv')\n",
    "    big_table_dir = datadir + 'big_table_full_v4.csv'\n",
    "    univ = univ_setup(big_table_dir)\n",
    "    # filt_by_name(univ) # This is slow！\n",
    "    with open(datadir + 'univ.pkl','wb') as fh:\n",
    "        pickle.dump(univ, fh)\n",
    "end = time()\n",
    "print('%f seconds' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Filt the universe ###\n",
    "print('Filt beforehand')\n",
    "filt_na(univ)\n",
    "filt_byval(univ, 'price', 10)\n",
    "filt_byval(univ, 'not_in_MA', 0)\n",
    "filt_byval(univ, 'volume', 1500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "### model configuration ###\n",
    "print('Calculate factors')\n",
    "# define and calculate all factors\n",
    "factors = alpha_four_factors(univ)\n",
    "\n",
    "# concat into factor exposure matrices\n",
    "factor_exp_mat = combine_factors(factors)\n",
    "\n",
    "# Preprocessing factor expsure matrices\n",
    "print('Scale each factor')\n",
    "factor_exp_mat = process_batch(factor_exp_mat, standardize)\n",
    "print('Winsorize with +/- 3 std')\n",
    "factor_exp_mat = process_batch(factor_exp_mat, winsorize_std)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# const setup\n",
    "factor_names = [k for k in factors.keys()]\n",
    "datelst = sorted(factor_exp_mat.keys())\n",
    "N_f, N_T = len(factor_names), len(datelst)\n",
    "\n",
    "# Calc stock returns\n",
    "rebal = 1\n",
    "ret_series = log_return(univ, -rebal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run backtest\n",
    "dstart = datetime(2014, 1, 1)\n",
    "dend = datetime(2016, 12, 31)\n",
    "print('Start backtest from %s to %s' % (dstart.strftime('%Y/%m/%d'), dend.strftime('%Y/%m/%d')))\n",
    "ts = time()\n",
    "# ptfl_fin, pnl, fr_hist = backtest_batch(univ, factor_exp_mat, ret_series, dstart, dend, silent=False)\n",
    "ptfl_fin, pnl, fr_hist = backtest_multi_period_rebalance(univ, factor_exp_mat, ret_series, dstart, dend, rebal, silent=False)\n",
    "te = time()\n",
    "print(te - ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "pdb.runcall(backtest_multi_period_rebalance, univ, factor_exp_mat, ret_series, dstart, dend, rebal, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# simple_pa(pnl)\n",
    "pmfc = (cagr(pnl), vol(pnl), sharpe_ratio(pnl), max_drawdown(pnl), drawdown_length(pnl))\n",
    "print('CAGR:%f \\nVolatility:%f\\nSharpe_ratio:%f\\nMax drawdown: %f\\nDrawdown length: %d\\n' % pmfc)\n",
    "\n",
    "nowstr = datetime.now().strftime('%Y%m%d_%H:%M:%S')\n",
    "pnl['cumpnl'] = np.cumsum(pnl['pnl'])\n",
    "plot_nav(pnl)\n",
    "\n",
    "pnl.to_csv('./output/pnl_series_' + nowstr + '.csv', index=False)\n",
    "fr_hist.to_csv('./output/fitted_factor_return_' + nowstr + '.csv', index=False)\n",
    "# plot_nav(pnl, savedir = './output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "factor_names = fr_hist.columns[1:]\n",
    "for name in factor_names:\n",
    "    plt.plot(fr_hist[name])\n",
    "    plt.legend(loc=0, prop={'size':8})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
