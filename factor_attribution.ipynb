{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from time import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from setup.univ_setup import *\n",
    "from factor_mining.combine_factors import *\n",
    "from factor_mining.factor_preprocessing import *\n",
    "from performance_analysis.pa_core import *\n",
    "\n",
    "from backtest.BackTestSinglePeriod import *\n",
    "from backtest.BackTest import *\n",
    "from backtest.percentile_portfolio import *\n",
    "\n",
    "from factor_mining.attribution.factor_correlation import *\n",
    "\n",
    "from factor_mining.Mark0 import * # This is alpha file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class BackTestSinglePeriod(object):\n",
    "# \t# This serves as an abstract base class\n",
    "# \t# Each strategy should have its own version of single period backtest caclculator derived from this class\n",
    "\n",
    "# \tdef get_config(self):\n",
    "# \t\tassert False\n",
    "\n",
    "# \tdef get_func_name(self):\n",
    "# \t\tassert False\n",
    "\n",
    "# \tdef calc_pnl(self, univ, factor_exp_mat, t, **kwargs):\n",
    "# \t\tassert False\n",
    "        \n",
    "# class BackTest(object):\n",
    "# \tdef __init__(self, univ:dict, factor_exp_mat:dict, daterange:list, sp_calc:BackTestSinglePeriod, rebal=1):\n",
    "# \t\tself.univ = univ\n",
    "# \t\tself.factor_exp_mat = factor_exp_mat\n",
    "# \t\tself.dstart, self.dend = np.min(daterange), np.max(daterange)\n",
    "# \t\tself.rebal = rebal\n",
    "# \t\tself.sp_calc = sp_calc\n",
    "# \t\tself.has_pnl, self.has_pa = False, False\n",
    "\n",
    "# \tdef get_config(self):\n",
    "# \t\tconfig = {}\n",
    "# \t\tconfig['Strategy Name'] = self.sp_calc.get_func_name()\n",
    "# \t\tconfig['Strategy config'] = self.sp_calc.get_config()\n",
    "# \t\tconfig['Date range'] = [self.dstart.strftime('%Y-%m-%d'), self.dend.strftime('%Y-%m-%d')]\n",
    "# \t\tconfig['Rebalance period'] = self.rebal\n",
    "\n",
    "# \t\tif self.has_pnl:\n",
    "# \t\t\tpass\n",
    "\t\t\n",
    "# \t\tif self.has_pa:\n",
    "# \t\t\tpass\n",
    "\n",
    "# \t\treturn config\n",
    "\n",
    "# \tdef calc_pnl(self, **kwargs):\n",
    "# \t\tdatelst = sorted(self.univ.keys())\n",
    "# \t\ttin_lst, ptfl_lst, pnl_lst = [], [], []\n",
    "# \t\tcount = 0\n",
    "# \t\tfor t in datelst:\n",
    "# \t\t\tif t < self.dstart or t > self.dend:\n",
    "# \t\t\t\tcontinue\n",
    "\n",
    "# \t\t\tif count == 0:\n",
    "# \t\t\t\tptfl_sp, pnl_sp = self.sp_calc.calc_pnl(self.univ, self.factor_exp_mat, t, **kwargs)\n",
    "# \t\t\telse:\n",
    "# \t\t\t\tret_name = 'f_log_ret_1'\n",
    "# \t\t\t\top_na = pd.merge(ptfl_sp, univ[t], on='ticker', how='inner') # This stands for old portfolio, new analytics\n",
    "# \t\t\t\tpnl_sp = np.dot(op_na['weight'], op_na[ret_name])\n",
    "\n",
    "# \t\t\ttin_lst.append(t)\n",
    "# \t\t\tptfl_lst.append(ptfl_sp.copy())\n",
    "# \t\t\tpnl_lst.append(pnl_sp)\n",
    "\n",
    "# \t\t\tcount -= 1\n",
    "# \t\t\tcount %= self.rebal\n",
    "\n",
    "# \t\tself.pnl_lst = pd.DataFrame({'date':tin_lst, 'pnl':pnl_lst})\n",
    "# \t\tself.ptfl_lst = ptfl_lst\n",
    "# \t\tself.has_pnl = True\n",
    "# \t\treturn ptfl_lst, pnl_lst\n",
    "\n",
    "# \tdef simple_pa(self, **kwargs):\n",
    "# \t\tself.pa = simple_pa(self.pnl_lst)\n",
    "# \t\tself.has_pa = True\n",
    "        \n",
    "# class PercentilePtflSpcalc(BackTestSinglePeriod):\n",
    "# \tdef __init__(self, signal, sel_range, weighting='market_cap'):\n",
    "# \t\tself.signal = signal\n",
    "# \t\tself.sel_range = sel_range\n",
    "# \t\tself.weighting = weighting\n",
    "\n",
    "# \tdef get_config(self):\n",
    "# \t\tconfig = {}\n",
    "# \t\tconfig['Signal variable'] = self.signal\n",
    "# \t\tconfig['Selection range'] = self.sel_range\n",
    "# \t\tconfig['Weighting'] = self.weighting\n",
    "# \t\treturn config\n",
    "\n",
    "# \tdef get_func_name(self):\n",
    "# \t\treturn 'Percentile Portfolio'\n",
    "\n",
    "# \tdef calc_pnl(self, univ, factor_exp_mat, t, **kwargs):\n",
    "# \t\tret_name = 'f_log_ret_1'\n",
    "# \t\tuniv_sp, factor_exp_mat_sp = univ[t].copy(), factor_exp_mat[t].copy()\n",
    "# \t\tif 'demean' in kwargs:\n",
    "# \t\t\tif kwargs['demean'] == 'industry':\n",
    "# \t\t\t\tdemean = kwargs['demean']\n",
    "# \t\t\t\tuniv_sp['f_log_ret_1_demean'] = univ_sp[ret_name] - univ_sp.groupby(demean)[ret_name].transform('mean')           \n",
    "# \t\t\t\tret_name = 'f_log_ret_1_demean'\n",
    "\n",
    "# \t\tpct_low, pct_high = np.min(self.sel_range), np.max(self.sel_range)\n",
    "# \t\tsignal_var = np.asarray(factor_exp_mat_sp[self.signal])\n",
    "# \t\tcutoff_low, cutoff_high = np.percentile(signal_var[~np.isnan(signal_var)], [pct_low, pct_high])\n",
    "# \t\tix_in = (signal_var >= cutoff_low) * (signal_var <= cutoff_high)\n",
    "# \t\tticker_in = factor_exp_mat_sp['ticker'][ix_in]\n",
    "\n",
    "# \t\tptfl = univ_sp.loc[univ_sp['ticker'].isin(ticker_in), :]\n",
    "# \t\tif self.weighting == 'market_cap':\n",
    "# \t\t\tptfl['weight'] = ptfl['market_cap']\n",
    "# \t\telif self.weighting == 'equal':\n",
    "# \t\t\tptfl['weight'] = [1] * len(ptfl.index)\n",
    "# \t\telse:\n",
    "# \t\t\traise('unknown weighting method', self.weighting)\n",
    "\n",
    "# \t\tptfl['weight'] = ptfl['weight'] / np.nansum(ptfl['weight']) # normalize to 1\n",
    "# \t\tpnl_sp = np.dot(ptfl['weight'], ptfl[ret_name])\n",
    "# \t\tptfl_sp = ptfl[['date', 'ticker', 'weight']]\n",
    "# \t\treturn ptfl_sp, pnl_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup R3000 universe\n",
      "use existing binary file\n",
      "0.481927 seconds\n"
     ]
    }
   ],
   "source": [
    "### universe setup ###\n",
    "print('Setup R3000 universe')\n",
    "datadir = '/home/derek-qi/Documents/R3000_Data/data/r3000/'\n",
    "start = time()\n",
    "if os.path.exists(datadir + 'univ.pkl'):\n",
    "    print('use existing binary file')\n",
    "    with open(datadir + 'univ.pkl', 'rb') as univ_fh:\n",
    "        univ = pickle.load(univ_fh)\n",
    "    \n",
    "else:\n",
    "    print('construct from csv')\n",
    "    big_table_dir = datadir + 'big_table_full_v4.csv'\n",
    "    univ = univ_setup(big_table_dir)\n",
    "    # filt_by_name(univ) # This is slow！\n",
    "    with open(datadir + 'univ.pkl','wb') as fh:\n",
    "        pickle.dump(univ, fh)\n",
    "end = time()\n",
    "print('%f seconds' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filt beforehand\n"
     ]
    }
   ],
   "source": [
    "### Filt the universe ###\n",
    "print('Filt beforehand')\n",
    "filt_na(univ)\n",
    "filt_byval(univ, 'in_r3000', 0)\n",
    "filt_byval(univ, 'price', 10)\n",
    "filt_byval(univ, 'not_in_MA', 0)\n",
    "filt_byval(univ, 'volume', 1500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate factors\n",
      "Scale each factor\n",
      "Winsorize with +/- 3 std\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "### model configuration ###\n",
    "print('Calculate factors')\n",
    "# define and calculate all factors\n",
    "factors = alpha_four_factors(univ)\n",
    "\n",
    "# concat into factor exposure matrices\n",
    "factor_exp_mat = combine_factors(factors)\n",
    "\n",
    "# Preprocessing factor expsure matrices\n",
    "print('Scale each factor')\n",
    "factor_exp_mat = process_batch(factor_exp_mat, standardize)\n",
    "print('Winsorize with +/- 3 std')\n",
    "factor_exp_mat = process_batch(factor_exp_mat, winsorize_std)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# datelst = sorted(univ.keys())\n",
    "# crdf = factor_correlation(univ, factor_exp_mat, lag = 0, demean='industry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# factor_correlation_plot(crdf, ma=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spcalc = PercentilePtflSpcalc(signal='log_market_cap', sel_range=[80, 100])\n",
    "bt = BackTest(univ=univ, factor_exp_mat=factor_exp_mat, daterange=[datetime(2014, 1, 1), datetime(2016, 12, 31)], sp_calc=spcalc, rebal=4)\n",
    "ptfl_lst, pnl_lst = bt.calc_pnl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "rebal = [1, 4]\n",
    "factor_names = factor_exp_mat[datelst[0]].columns[2:].tolist()\n",
    "step = 5\n",
    "ranges = [[i * step, (i + 1) * step] for i in range(100//step)]\n",
    "daterange = [datetime(2014, 1, 1), datetime(2016, 12, 31)]\n",
    "config_iter = product(rebal, factor_names, ranges)\n",
    "iter_result = {}\n",
    "for r, f, g in config_iter:\n",
    "#     print(r,f,g)\n",
    "    spcalc = PercentilePtflSpcalc(signal=f, sel_range=g, weighting='equal')\n",
    "    bt = BackTest(univ, factor_exp_mat, daterange, spcalc, rebal=r)\n",
    "    ptfl_lst, pnl_lst = bt.calc_pnl(demean='industry')\n",
    "    k = f + '_' + str(g[0]) + '_' + str(g[1]) + '_' + str(r)\n",
    "    iter_result[k] = (np.nanmean(pnl_lst), np.sqrt(np.nanvar(pnl_lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in factor_names:\n",
    "# n = 'momentum'\n",
    "    c = len(pnl_lst)\n",
    "    x = [5*i for i in range(20)]\n",
    "    y_1 = [iter_result[n+'_'+str(i)+'_'+str(i+5)+'_1'][0] for i in x]\n",
    "    s_1 = [iter_result[n+'_'+str(i)+'_'+str(i+5)+'_1'][1] / np.sqrt(c) for i in x]\n",
    "    y_4 = [iter_result[n+'_'+str(i)+'_'+str(i+5)+'_4'][0] for i in x]\n",
    "    s_4 = [iter_result[n+'_'+str(i)+'_'+str(i+5)+'_4'][1] / np.sqrt(c) for i in x]\n",
    "    \n",
    "    # Here comes the plots\n",
    "    bar_width = 2\n",
    "    week = plt.bar(np.array(x), y_1, width=bar_width, yerr=s_1, color='b', label='week')\n",
    "    month = plt.bar(np.array(x) + bar_width, y_4, width=bar_width, yerr=s_4, color='g', label='month')\n",
    "\n",
    "    plt.xlabel('Percentile')\n",
    "    plt.ylabel('Average period log returns')\n",
    "    plt.title(n)\n",
    "    plt.xticks(np.array(x) + bar_width, x)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
