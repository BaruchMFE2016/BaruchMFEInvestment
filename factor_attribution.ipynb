{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from setup.univ_setup import *\n",
    "from setup.utils import *\n",
    "from factor_mining.combine_factors import *\n",
    "from factor_mining.factor_preprocessing import *\n",
    "from performance_analysis.pa_core import *\n",
    "\n",
    "from backtest.BackTestSinglePeriod import *\n",
    "from backtest.BackTest import *\n",
    "from backtest.percentile_portfolio import *\n",
    "\n",
    "from factor_mining.attribution.factor_correlation import *\n",
    "\n",
    "from factor_mining.Mark0 import * # This is alpha file\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup R3000 universe\n",
      "use existing binary file\n",
      "0.448636 seconds\n",
      "Calculate factors\n",
      "Filt the untradables\n",
      "Scale each factor\n",
      "Winsorize with +/- 3 std\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "### universe setup ###\n",
    "datadir = '/home/derek-qi/Documents/R3000_Data/data/r3000/'\n",
    "univ = univ_setup(datadir, silent=False)\n",
    "filt_na(univ)\n",
    "\n",
    "### model configuration ###\n",
    "print('Calculate factors')\n",
    "# define and calculate all factors\n",
    "factors = alpha_four_factors(univ)\n",
    "factor_names = list(factors.keys())\n",
    "\n",
    "# concat into factor exposure matrices\n",
    "factor_exp_mat = combine_factors(factors)\n",
    "filt_na(factor_exp_mat)\n",
    "\n",
    "### Filt the illiquid names within universe ###\n",
    "print('Filt the untradables')\n",
    "\n",
    "filt_byval(univ, 'in_r3000', 0)\n",
    "filt_byval(univ, 'not_in_MA', 0)\n",
    "filt_byval(univ, 'price', 10)\n",
    "filt_byval(univ, 'volume', 1500000)\n",
    "factor_exp_mat = merge(factor_exp_mat, univ, right_cols=['f_log_ret_1', 'industry'])\n",
    "\n",
    "# Preprocessing factor expsure matrices\n",
    "print('Scale each factor')\n",
    "factor_exp_mat = process_batch(factor_exp_mat, standardize, factor_names=factor_names)\n",
    "print('Winsorize with +/- 3 std')\n",
    "factor_exp_mat = process_batch(factor_exp_mat, winsorize_std, factor_names=factor_names)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-04-30 00:00:00 2017-04-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "datelst = sorted(univ.keys())\n",
    "print(datelst[0], datelst[-1])\n",
    "start_date = datetime(2011, 1, 1)\n",
    "end_date = datetime(2016, 12, 31)\n",
    "# crdf = factor_correlation(univ, factor_exp_mat, lag = 0, demean='industry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['log_market_cap', 'momentum', 'vol60', 'beta']\n"
     ]
    }
   ],
   "source": [
    "factor_names = list(factors.keys())\n",
    "print(factor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spcalc = PercentilePtflSpcalc(signal='log_market_cap', sel_range=[95, 100])\n",
    "bt = BackTest(univ=univ, factor_exp_mat=factor_exp_mat, daterange=[start_date, end_date], sp_calc=spcalc, rebal=1)\n",
    "ptfl_lst_95_100, pnl_lst_95_100 = bt.calc_pnl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAGR :\t 0.105226838108\n",
      "Volatility :\t 0.141529264935\n",
      "Sharpe :\t 0.706925152926\n",
      "Max_Drawdown :\t 0.168891917414\n",
      "Drawdown_Length :\t 21\n"
     ]
    }
   ],
   "source": [
    "bt.calc_pa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%prun\n",
    "for fn in factor_names:\n",
    "    # Top 5 percent\n",
    "    spcalc = PercentilePtflSpcalc(signal=fn, sel_range=[95, 100])\n",
    "    bt = BackTest(univ=univ, factor_exp_mat=factor_exp_mat, daterange=[start_date, end_date], sp_calc=spcalc, rebal=1)\n",
    "    ptfl_lst_95_100, pnl_lst_95_100 = bt.calc_pnl()\n",
    "    # Bottom 5 percent\n",
    "    spcalc = PercentilePtflSpcalc(signal=fn, sel_range=[0, 5])\n",
    "    bt = BackTest(univ=univ, factor_exp_mat=factor_exp_mat, daterange=[start_date, end_date], sp_calc=spcalc, rebal=1)\n",
    "    ptfl_lst_0_5, pnl_lst_0_5 = bt.calc_pnl()\n",
    "\n",
    "    pnl = np.asarray(pnl_lst_95_100) - np.asarray(pnl_lst_0_5)\n",
    "    plt.plot(np.cumsum(pnl))\n",
    "    plt.xlabel(fn)\n",
    "    plt.ylabel('Cumulative Pnl')\n",
    "    plt.show()\n",
    "    \n",
    "    sharpe = np.nanmean(pnl) / np.sqrt(np.nanvar(pnl)) * np.sqrt(52)\n",
    "    print('Volatility: %f' % np.sqrt(np.nanvar(pnl) * 52))\n",
    "    print('Sharpe Ratio: %f' % sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from itertools import product\n",
    "rebal = [1]\n",
    "# factor_names = ['momentum', 'vol60', 'beta']\n",
    "step = 5\n",
    "ranges = [[i * step, (i + 1) * step] for i in range(100//step)]\n",
    "daterange = [start_date, end_date]\n",
    "config_iter = product(rebal, factor_names, ranges)\n",
    "iter_result = {}\n",
    "for r, f, g in config_iter:\n",
    "#     print(r,f,g)\n",
    "    spcalc = PercentilePtflSpcalc(signal=f, sel_range=g, weighting='equal')\n",
    "    bt = BackTest(univ, factor_exp_mat, daterange, spcalc, rebal=r)\n",
    "    ptfl_lst, pnl_lst = bt.calc_pnl(demean='industry')\n",
    "    k = f + '_' + str(g[0]) + '_' + str(g[1]) + '_' + str(r)\n",
    "    iter_result[k] = (np.nanmean(pnl_lst), np.sqrt(np.nanvar(pnl_lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in factor_names:\n",
    "    c = len(pnl_lst)\n",
    "    x = [5*i for i in range(20)]\n",
    "    y_1 = [iter_result[n+'_'+str(i)+'_'+str(i+5)+'_1'][0] for i in x]\n",
    "    s_1 = [iter_result[n+'_'+str(i)+'_'+str(i+5)+'_1'][1] / np.sqrt(c) for i in x]\n",
    "    \n",
    "    # Here comes the plots\n",
    "    bar_width = 2\n",
    "    week = plt.bar(np.array(x), y_1, width=bar_width, yerr=s_1, color='b')\n",
    "\n",
    "    plt.xlabel('Percentile')\n",
    "    plt.ylabel('Average period log returns')\n",
    "    plt.title(n)\n",
    "    plt.xticks(np.array(x) + bar_width, x)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
